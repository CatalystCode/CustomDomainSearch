{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a Custom Search Engine\n",
    "### Step 2 - Create Azure Search Index\n",
    "- Define new index structure\n",
    "- Create Azure Search index\n",
    "- Upload and index parsed content from step 1\n",
    "- Optional: Simple management of Azure Search index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import base packages\n",
    "import requests\n",
    "import json\n",
    "import csv\n",
    "import datetime\n",
    "import pytz\n",
    "import calendar\n",
    "import os\n",
    "import pyexcel as pe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, initialize Azure Search configuration parameters to be used for index creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This is the service you've already created in Azure Portal\n",
    "serviceName = 'your_azure_search_service_name'\n",
    "\n",
    "# Index to be created\n",
    "indexName = 'name_of_index_to_create'\n",
    "\n",
    "# Set your service API key, either via an environment variable or enter it below\n",
    "#apiKey = os.getenv('SEARCH_KEY_DEV', '')\n",
    "apiKey = 'your_azure_search_service_api_key'\n",
    "apiVersion = '2016-09-01'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the path to the parsed content file from step 1, and define a basic mapping of the input fields to the desired target field names in the new index. Input and output field names do not need to be the same. However, the target names should match the index definition in getIndexDefinition()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Input parsed content Excel file, e.g., output of step #1 in\n",
    "# https://github.com/CatalystCode/CustomSearch/tree/master/JupyterNotebooks/1-content_extraction.ipynb\n",
    "inputfile = os.path.join(os.getcwd(), '../sample/parsed_content.xlsx')\n",
    "\n",
    "# Define fields mapping from Excel file column names to search index field names (except Index)\n",
    "# Change this mapping to match your content fields and rename output fields as desired\n",
    "# Search field names should match their definition in getIndexDefinition()\n",
    "fields_map = [ ('File'            , 'File'),\n",
    "               ('ChapterTitle'    , 'ChapterTitle'),\n",
    "               ('SectionTitle'    , 'SectionTitle'),\n",
    "               ('SubsectionTitle' , 'SubsectionTitle'),\n",
    "               ('SubsectionText'  , 'SubsectionText'),\n",
    "               ('Keywords'        , 'Keywords') ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's define the structure of the new index to be created. In this example, all titles, content text and keywords fields are full-text searchable. Queries will use all searchable fields by default to retrieve a ranked list of results.\n",
    "\n",
    "For more details, refer to [Create an Azure Search Index](https://docs.microsoft.com/en-us/azure/search/search-what-is-an-index)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Fields: Index\tFile\tChapterTitle\tSectionTitle\tSubsectionTitle\t\tSubsectionText\tKeywords\n",
    "def getIndexDefinition():\n",
    "    return {\n",
    "        \"name\": indexName,  \n",
    "        \"fields\": [\n",
    "        {\"name\": \"Index\", \"type\": \"Edm.String\", \"key\": True, \"retrievable\": True, \"searchable\": False, \"filterable\": False, \"sortable\": True, \"facetable\": False},\n",
    "\n",
    "        {\"name\": \"File\", \"type\": \"Edm.String\", \"retrievable\": True, \"searchable\": False, \"filterable\": True, \"sortable\": True, \"facetable\": False},\n",
    "\n",
    "        {\"name\": \"ChapterTitle\", \"type\": \"Edm.String\", \"retrievable\": True, \"searchable\": True, \"filterable\": True, \"sortable\": True, \"facetable\": True},\n",
    "\n",
    "        {\"name\": \"SectionTitle\", \"type\": \"Edm.String\", \"retrievable\": True, \"searchable\": True, \"filterable\": True, \"sortable\": False, \"facetable\": True},\n",
    "\n",
    "        {\"name\": \"SubsectionTitle\", \"type\": \"Edm.String\", \"retrievable\": True, \"searchable\": True, \"filterable\": True, \"sortable\": True, \"facetable\": False},\n",
    "\n",
    "        {\"name\": \"SubsectionText\", \"type\": \"Edm.String\", \"retrievable\": True, \"searchable\": True, \"filterable\": False, \"sortable\": False, \"facetable\": False, \"analyzer\": \"en.microsoft\"},\n",
    "\n",
    "        {\"name\": \"Keywords\", \"type\": \"Edm.String\", \"retrievable\": True, \"searchable\": True, \"filterable\": False, \"sortable\": False, \"facetable\": False, \"analyzer\": \"en.microsoft\"}\n",
    "        ]\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Helper functions for basic REST API operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getServiceUrl():\n",
    "    return 'https://' + serviceName + '.search.windows.net'\n",
    "\n",
    "def getMethod(servicePath):\n",
    "    headers = {'Content-type': 'application/json', 'api-key': apiKey}\n",
    "    r = requests.get(getServiceUrl() + servicePath, headers=headers)\n",
    "    #print(r.text)\n",
    "    return r\n",
    "\n",
    "def postMethod(servicePath, body):\n",
    "    headers = {'Content-type': 'application/json', 'api-key': apiKey}\n",
    "    r = requests.post(getServiceUrl() + servicePath, headers=headers, data=body)\n",
    "    #print(r, r.text)\n",
    "    return r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Simple index management functions\n",
    "- Create a new index\n",
    "- Delete an existing index\n",
    "- Check if index exists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def createIndex():\n",
    "    indexDefinition = json.dumps(getIndexDefinition())  \n",
    "    servicePath = '/indexes/?api-version=%s' % apiVersion\n",
    "    r = postMethod(servicePath, indexDefinition)\n",
    "    #print r.text\n",
    "    if r.status_code == 201:\n",
    "       print('Index %s created' % indexName)   \n",
    "    else:\n",
    "       print('Failed to create index %s' % indexName)\n",
    "       exit(1)\n",
    "\n",
    "def deleteIndex():\n",
    "    servicePath = '/indexes/%s?api-version=%s&delete' % (indexName, apiVersion)\n",
    "    headers = {'Content-type': 'application/json', 'api-key': apiKey}\n",
    "    r = requests.delete(getServiceUrl() + servicePath, headers=headers)\n",
    "    #print(r.text)\n",
    "\n",
    "def getIndex():\n",
    "    servicePath = '/indexes/%s?api-version=%s' % (indexName, apiVersion)\n",
    "    r = getMethod(servicePath)\n",
    "    if r.status_code == 200:  \n",
    "       return True\n",
    "    else:\n",
    "       return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Helper functions to fetch one or more documents from the parsed content file\n",
    "\n",
    "Note: In this exercise, a *document* corresponds to one row from the parsed content Excel file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getDocumentObject():   \n",
    "    valarry = []\n",
    "    cnt = 1\n",
    "    records = pe.iget_records(file_name=inputfile)\n",
    "    for row in records:\n",
    "        outdict = {}\n",
    "        outdict['@search.action'] = 'upload'\n",
    "\n",
    "        if (row[fields_map[0][0]]):\n",
    "            outdict['Index'] = str(row['Index'])\n",
    "            for (in_fld, out_fld) in fields_map:\n",
    "                outdict[out_fld]  = row[in_fld]\n",
    "        valarry.append(outdict)\n",
    "        cnt+=1\n",
    "\n",
    "    return {'value' : valarry}\n",
    "\n",
    "def getDocumentObjectByChunk(start, end):   \n",
    "    valarry = []\n",
    "    cnt = 1\n",
    "    records = pe.iget_records(file_name=inputfile)\n",
    "    for i, row in enumerate(records):\n",
    "        if start <= i < end:\n",
    "            outdict = {}\n",
    "            outdict['@search.action'] = 'upload'\n",
    "\n",
    "            if (row[fields_map[0][0]]):\n",
    "                outdict['Index'] = str(row['Index'])\n",
    "                for (in_fld, out_fld) in fields_map:\n",
    "                    outdict[out_fld]  = row[in_fld]\n",
    "            valarry.append(outdict)\n",
    "            cnt+=1\n",
    "\n",
    "    return {'value' : valarry}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Main functions to upload and index documents in Azure Search\n",
    "\n",
    "Three methods are provided:\n",
    "- Upload all documents (rows) at once\n",
    "- Upload documents in chunks\n",
    "- Upload one document at a time\n",
    "\n",
    "**Note:** The method choice depends on the content size and whether it would fit in one or more REST request. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Upload content for indexing in one request if content is not too large\n",
    "def uploadDocuments():\n",
    "    documents = json.dumps(getDocumentObject())\n",
    "    servicePath = '/indexes/' + indexName + '/docs/index?api-version=' + apiVersion\n",
    "    r = postMethod(servicePath, documents)\n",
    "    if r.status_code == 200:\n",
    "        print('Success: %s' % r)   \n",
    "    else:\n",
    "        print('Failure: %s' % r.text)\n",
    "        exit(1)\n",
    "\n",
    "# Upload content for indexing in chunks if content is too large for one request\n",
    "def uploadDocumentsInChunks(chunksize):\n",
    "    records = pe.iget_records(file_name=inputfile)\n",
    "    cnt  = 0\n",
    "    for row in records:\n",
    "        cnt += 1\n",
    "\n",
    "    for chunk in range(cnt/chunksize + 1):\n",
    "        print('Processing chunk number %d ...' % chunk)\n",
    "        start = chunk * chunksize\n",
    "        end   = start + chunksize\n",
    "        documents = json.dumps(getDocumentObjectByChunk(start, end))\n",
    "        servicePath = '/indexes/' + indexName + '/docs/index?api-version=' + apiVersion\n",
    "        r = postMethod(servicePath, documents)\n",
    "        if r.status_code == 200:\n",
    "            print('Success: %s' % r)   \n",
    "        else:\n",
    "            print('Failure: %s' % r.text)\n",
    "    return\n",
    "\n",
    "# Upload content for indexing one document at a time\n",
    "def uploadDocumentsOneByOne():\n",
    "    records = pe.iget_records(file_name=inputfile)\n",
    "    valarry = []\n",
    "    for i, row in enumerate(records):\n",
    "        outdict = {}\n",
    "        outdict['@search.action'] = 'upload'\n",
    "\n",
    "        if (row[fields_map[0][0]]):\n",
    "            outdict['Index'] = str(row['Index'])\n",
    "            for (in_fld, out_fld) in fields_map:\n",
    "                outdict[out_fld]  = row[in_fld]\n",
    "            valarry.append(outdict)\n",
    "\n",
    "        documents = json.dumps({'value' : valarry})\n",
    "        servicePath = '/indexes/' + indexName + '/docs/index?api-version=' + apiVersion\n",
    "        r = postMethod(servicePath, documents)\n",
    "        if r.status_code == 200:\n",
    "            print('%d Success: %s' % (i,r))   \n",
    "        else:\n",
    "            print('%d Failure: %s' % (i, r.text))\n",
    "            exit(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Helper functions to check and query an index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def printDocumentCount():\n",
    "    servicePath = '/indexes/' + indexName + '/docs/$count?api-version=' + apiVersion   \n",
    "    getMethod(servicePath)\n",
    "\n",
    "def sampleQuery(query, ntop=3):\n",
    "    servicePath = '/indexes/' + indexName + '/docs?api-version=%s&search=%s&$top=%d' % \\\n",
    "        (apiVersion, query, ntop)\n",
    "    getMethod(servicePath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create index and upload all parsed content\n",
    "\n",
    "Now let's create the index, or delete and re-create the index if it exists, then upload all parsed documents in chunks. The small sample can be uploaded all at once, but the full tax code content would require multiple requests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Choose upload method to be used. Options: 'all', chunks' or 'one'\n",
    "upload_method     = 'chunks'\n",
    "upload_chunk_size = 50\n",
    "\n",
    "# Create index if it does not exist\n",
    "if not getIndex():\n",
    "    createIndex()    \n",
    "else:\n",
    "    ans = raw_input('Index %s already exists ... Do you want to delete it? [Y/n]' % indexName)\n",
    "    if ans.lower() == 'y':\n",
    "        deleteIndex()\n",
    "        print('Re-creating index %s ...' % indexName)\n",
    "        createIndex()\n",
    "    else:\n",
    "        print('Index %s is not deleted ... New content will be added to existing index' % indexName)\n",
    "\n",
    "if upload_method == 'all':\n",
    "    uploadDocuments()\n",
    "elif upload_methos == 'chunks':\n",
    "    uploadDocumentsInChunks(upload_chunk_size)\n",
    "else:\n",
    "    uploadDocumentsOneByOne()\n",
    "    \n",
    "# Verify and test the newly created index\n",
    "printDocumentCount()\n",
    "sampleQuery('child tax credit')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The content is now ready for interactive or batch queries, as demonstrated in step #3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
